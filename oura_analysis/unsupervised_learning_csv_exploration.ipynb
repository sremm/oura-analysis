{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oura_analysis.loader import OuraDataNumeric\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "oura_data = OuraDataNumeric.from_path(\"../data/oura_2019-06-01_2024-01-01_trends.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_, counts]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are all the data columns\n",
    "all_table_data = oura_data.data_table\n",
    "print(all_table_data.columns)\n",
    "print(\"Number of columns\", len(all_table_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_column_values(df: pd.DataFrame):\n",
    "    result = df.copy()\n",
    "\n",
    "    cols_min = df.min(axis=0)\n",
    "    zero_min = result - cols_min\n",
    "    result = zero_min / zero_min.max(axis=0)\n",
    "    result -= 0.5\n",
    "    result *= 2\n",
    "    return result\n",
    "\n",
    "\n",
    "# prepare oura data for clustering\n",
    "# convert dates to floats\n",
    "date_index = all_table_data[\"date\"]\n",
    "original_index_number = date_index.index.values\n",
    "columns_to_drop = [\"date\", \"Bedtime Start\", \"Bedtime End\", \"HRV Balance Score\"]\n",
    "without_some_cols = all_table_data.drop(axis=1, labels=columns_to_drop)\n",
    "# drop any rows that have nans, since the clustering does not accept those\n",
    "has_nan = without_some_cols.isna()\n",
    "num_col_nan_sums = has_nan.sum(axis=0)\n",
    "num_rows_nan_sums = has_nan.sum(axis=1)\n",
    "\n",
    "rows_that_have_nan_values = num_rows_nan_sums > 0\n",
    "num_days_with_nan_values = rows_that_have_nan_values.sum()\n",
    "print(\"num rows discarded: \", num_days_with_nan_values)\n",
    "\n",
    "feature_prep = without_some_cols[rows_that_have_nan_values == False]\n",
    "print(\"num data rows to use: \", len(feature_prep))\n",
    "normalised_features = normalise_column_values(feature_prep)\n",
    "X = normalised_features\n",
    "\n",
    "features_used_with_date = X.copy()\n",
    "features_used_with_date[\"original_index_number\"] = original_index_number[rows_that_have_nan_values == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_threshold = None\n",
    "n_clusters = 7\n",
    "clustering = AgglomerativeClustering(n_clusters=n_clusters, distance_threshold=distance_threshold, compute_distances=True).fit(X)\n",
    "print(\"num unique labels: \", len(set(clustering.labels_)))\n",
    "print()\n",
    "\n",
    "features_used_with_date[\"category_from_clustering\"] = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dendrogram(clustering, truncate_mode=\"level\", p=4, labels=clustering.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def normalise_column_values(df: pd.DataFrame):\n",
    "    result = df.copy()\n",
    "\n",
    "    cols_min = df.min(axis=0)\n",
    "    zero_min = result - cols_min\n",
    "    result = zero_min / zero_min.max(axis=0)\n",
    "    result -= 0.5\n",
    "    result *= 2\n",
    "    return result\n",
    "\n",
    "\n",
    "normalised_data = normalise_column_values(features_used_with_date)\n",
    "normalised_data = normalised_data.sort_values(\"category_from_clustering\")  # original_index_number # category_from_clustering\n",
    "fig = go.Figure([go.Heatmap(z=normalised_data.values, y=np.arange(len(normalised_data)), x=normalised_data.columns, colorscale=\"RdBu\")])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could we now get what scores influnce what group, read that i could now do a random forest which has a built in feature importance metric\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RClf\n",
    "\n",
    "model = RClf(n_estimators=100)\n",
    "model.fit(X, clustering.labels_)\n",
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature Ranking:\")\n",
    "\n",
    "for rank in range(len(importances)):\n",
    "    feature_id = indices[rank]\n",
    "    print(f\"{rank} - {clustering.feature_names_in_[feature_id]} ({importances[feature_id]})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oura-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
